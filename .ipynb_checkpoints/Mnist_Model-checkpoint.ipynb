{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "training accuracy 0.1203\n",
      "training accuracy 0.3787\n",
      "training accuracy 0.4456\n",
      "training accuracy 0.3639\n",
      "training accuracy 0.395\n",
      "training accuracy 0.3825\n",
      "training accuracy 0.5644\n",
      "training accuracy 0.6145\n",
      "training accuracy 0.6441\n",
      "training accuracy 0.6673\n",
      "training accuracy 0.5531\n",
      "training accuracy 0.6936\n",
      "training accuracy 0.7245\n",
      "training accuracy 0.7634\n",
      "training accuracy 0.8063\n",
      "training accuracy 0.7462\n",
      "training accuracy 0.7594\n",
      "training accuracy 0.8099\n",
      "training accuracy 0.8252\n",
      "training accuracy 0.8155\n",
      "training accuracy 0.7522\n",
      "training accuracy 0.781\n",
      "training accuracy 0.7978\n",
      "training accuracy 0.8318\n",
      "training accuracy 0.8462\n",
      "training accuracy 0.8606\n",
      "training accuracy 0.8091\n",
      "training accuracy 0.821\n",
      "training accuracy 0.8678\n",
      "training accuracy 0.8629\n",
      "training accuracy 0.8641\n",
      "training accuracy 0.8593\n",
      "training accuracy 0.8616\n",
      "training accuracy 0.8548\n",
      "training accuracy 0.8385\n",
      "training accuracy 0.7987\n",
      "training accuracy 0.7801\n",
      "training accuracy 0.7671\n",
      "training accuracy 0.805\n",
      "training accuracy 0.8217\n",
      "training accuracy 0.8603\n",
      "training accuracy 0.8622\n",
      "training accuracy 0.8485\n",
      "training accuracy 0.7728\n",
      "training accuracy 0.8179\n",
      "training accuracy 0.837\n",
      "training accuracy 0.8342\n",
      "training accuracy 0.8673\n",
      "training accuracy 0.859\n",
      "training accuracy 0.8751\n",
      "training accuracy 0.8521\n",
      "training accuracy 0.844\n",
      "training accuracy 0.8482\n",
      "training accuracy 0.8741\n",
      "training accuracy 0.8619\n",
      "training accuracy 0.8708\n",
      "training accuracy 0.8859\n",
      "training accuracy 0.8756\n",
      "training accuracy 0.8876\n",
      "training accuracy 0.8663\n",
      "training accuracy 0.8938\n",
      "training accuracy 0.8863\n",
      "training accuracy 0.877\n",
      "training accuracy 0.8864\n",
      "training accuracy 0.8785\n",
      "training accuracy 0.8841\n",
      "training accuracy 0.8922\n",
      "training accuracy 0.8749\n",
      "training accuracy 0.8674\n",
      "training accuracy 0.8881\n",
      "training accuracy 0.8915\n",
      "training accuracy 0.8869\n",
      "training accuracy 0.8909\n",
      "training accuracy 0.7887\n",
      "training accuracy 0.8445\n",
      "training accuracy 0.874\n",
      "training accuracy 0.8942\n",
      "training accuracy 0.896\n",
      "training accuracy 0.8897\n",
      "training accuracy 0.8851\n",
      "training accuracy 0.8924\n",
      "training accuracy 0.8887\n",
      "training accuracy 0.871\n",
      "training accuracy 0.8622\n",
      "training accuracy 0.883\n",
      "training accuracy 0.8842\n",
      "training accuracy 0.8932\n",
      "training accuracy 0.8976\n",
      "training accuracy 0.889\n",
      "training accuracy 0.8675\n",
      "training accuracy 0.8926\n",
      "training accuracy 0.8967\n",
      "training accuracy 0.8936\n",
      "training accuracy 0.8892\n",
      "training accuracy 0.8937\n",
      "training accuracy 0.8945\n",
      "training accuracy 0.8946\n",
      "training accuracy 0.8923\n",
      "training accuracy 0.8916\n",
      "training accuracy 0.865\n",
      "training accuracy 0.8902\n",
      "training accuracy 0.897\n",
      "training accuracy 0.8818\n",
      "training accuracy 0.8739\n",
      "training accuracy 0.8919\n",
      "training accuracy 0.8997\n",
      "training accuracy 0.8954\n",
      "training accuracy 0.8996\n",
      "training accuracy 0.8751\n",
      "training accuracy 0.8963\n",
      "training accuracy 0.9004\n",
      "training accuracy 0.898\n",
      "training accuracy 0.9016\n",
      "training accuracy 0.8621\n",
      "training accuracy 0.81\n",
      "training accuracy 0.8117\n",
      "training accuracy 0.8556\n",
      "training accuracy 0.867\n",
      "training accuracy 0.8847\n",
      "training accuracy 0.9019\n",
      "training accuracy 0.8843\n",
      "training accuracy 0.887\n",
      "training accuracy 0.8383\n",
      "training accuracy 0.8566\n",
      "training accuracy 0.8997\n",
      "training accuracy 0.8917\n",
      "training accuracy 0.9001\n",
      "training accuracy 0.8801\n",
      "training accuracy 0.9014\n",
      "training accuracy 0.8951\n",
      "training accuracy 0.8963\n",
      "training accuracy 0.8991\n",
      "training accuracy 0.8963\n",
      "training accuracy 0.8998\n",
      "training accuracy 0.901\n",
      "training accuracy 0.8966\n",
      "training accuracy 0.8953\n",
      "training accuracy 0.9056\n",
      "training accuracy 0.9053\n",
      "training accuracy 0.9007\n",
      "training accuracy 0.8968\n",
      "training accuracy 0.8988\n",
      "training accuracy 0.8977\n",
      "training accuracy 0.8956\n",
      "training accuracy 0.8772\n",
      "training accuracy 0.9015\n",
      "training accuracy 0.8868\n",
      "training accuracy 0.8882\n",
      "training accuracy 0.8765\n",
      "training accuracy 0.8991\n",
      "training accuracy 0.9059\n",
      "training accuracy 0.8953\n",
      "training accuracy 0.8968\n",
      "training accuracy 0.897\n",
      "training accuracy 0.8948\n",
      "training accuracy 0.9046\n",
      "training accuracy 0.8972\n",
      "training accuracy 0.8883\n",
      "training accuracy 0.879\n",
      "training accuracy 0.848\n",
      "training accuracy 0.8862\n",
      "training accuracy 0.8976\n",
      "training accuracy 0.8983\n",
      "training accuracy 0.8985\n",
      "training accuracy 0.8974\n",
      "training accuracy 0.9048\n",
      "training accuracy 0.904\n",
      "training accuracy 0.9066\n",
      "training accuracy 0.8971\n",
      "training accuracy 0.904\n",
      "training accuracy 0.8984\n",
      "training accuracy 0.8981\n",
      "training accuracy 0.9006\n",
      "training accuracy 0.8915\n",
      "training accuracy 0.8889\n",
      "training accuracy 0.9065\n",
      "training accuracy 0.904\n",
      "training accuracy 0.9021\n",
      "training accuracy 0.9\n",
      "training accuracy 0.8979\n",
      "training accuracy 0.8899\n",
      "training accuracy 0.9007\n",
      "training accuracy 0.901\n",
      "training accuracy 0.901\n",
      "training accuracy 0.9034\n",
      "training accuracy 0.9017\n",
      "training accuracy 0.9086\n",
      "training accuracy 0.8987\n",
      "training accuracy 0.899\n",
      "training accuracy 0.9088\n",
      "training accuracy 0.9081\n",
      "training accuracy 0.9084\n",
      "training accuracy 0.8999\n",
      "training accuracy 0.9072\n",
      "training accuracy 0.9071\n",
      "training accuracy 0.9068\n",
      "training accuracy 0.9071\n",
      "training accuracy 0.8986\n",
      "training accuracy 0.8945\n",
      "training accuracy 0.8953\n",
      "Done training!\n",
      "Exporting trained model to ./models/mnist/1\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "graph already contains one or more legacy init ops under the collection legacy_init_op.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2f477cd836f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m           \u001b[0mclassification_signature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   },\n\u001b[0;32m--> 119\u001b[0;31m   legacy_init_op=legacy_init_op)\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markkeinhorster/git/tensorflow_serving_weather_service/tf_weather_service/lib/python2.7/site-packages/tensorflow/python/saved_model/builder_impl.pyc\u001b[0m in \u001b[0;36madd_meta_graph_and_variables\u001b[0;34m(self, sess, tags, signature_def_map, assets_collection, legacy_init_op, clear_devices, main_op, strip_default_attrs)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmain_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m       \u001b[0;31m# Add legacy init op to the SavedModel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_add_legacy_init_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlegacy_init_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_main_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markkeinhorster/git/tensorflow_serving_weather_service/tf_weather_service/lib/python2.7/site-packages/tensorflow/python/saved_model/builder_impl.pyc\u001b[0m in \u001b[0;36m_maybe_add_legacy_init_op\u001b[0;34m(self, legacy_init_op)\u001b[0m\n\u001b[1;32m    152\u001b[0m         raise AssertionError(\n\u001b[1;32m    153\u001b[0m             \u001b[0;34m\"graph already contains one or more legacy init ops under the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \"collection {}.\".format(constants.LEGACY_INIT_OP_KEY))\n\u001b[0m\u001b[1;32m    155\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEGACY_INIT_OP_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegacy_init_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: graph already contains one or more legacy init ops under the collection legacy_init_op."
     ]
    }
   ],
   "source": [
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "#!/usr/bin/env python2.7\n",
    "r\"\"\"Train and export a simple Softmax Regression TensorFlow model.\n",
    "\n",
    "The model is from the TensorFlow \"MNIST For ML Beginner\" tutorial. This program\n",
    "simply follows all its training instructions, and uses TensorFlow SavedModel to\n",
    "export the trained model with proper signatures that can be loaded by standard\n",
    "tensorflow_model_server.\n",
    "\n",
    "Usage: mnist_saved_model.py [--training_iteration=x] [--model_version=y] \\\n",
    "export_dir\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# This is a placeholder for a Google-internal import.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "# Train model\n",
    "print('Training model...')\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "serialized_tf_example = tf.placeholder(tf.string, name='tf_example')\n",
    "feature_configs = {'x': tf.FixedLenFeature(shape=[784], dtype=tf.float32),}\n",
    "tf_example = tf.parse_example(serialized_tf_example, feature_configs)\n",
    "x = tf.identity(tf_example['x'], name='x')  # use tf.identity() to assign name\n",
    "y_ = tf.placeholder('float', shape=[None, 10])\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "y = tf.nn.softmax(tf.matmul(x, w) + b, name='y')\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "values, indices = tf.nn.top_k(y, 10)\n",
    "table = tf.contrib.lookup.index_to_string_table_from_tensor(\n",
    "  tf.constant([str(i) for i in xrange(10)]))\n",
    "prediction_classes = table.lookup(tf.to_int64(indices))\n",
    "for _ in range(500):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "    print('training accuracy %g' % sess.run(\n",
    "      accuracy, feed_dict={\n",
    "          x: mnist.test.images,\n",
    "          y_: mnist.test.labels\n",
    "      }))\n",
    "print('Done training!')\n",
    "\n",
    "# Export model\n",
    "# WARNING(break-tutorial-inline-code): The following code snippet is\n",
    "# in-lined in tutorials, please update tutorial documents accordingly\n",
    "# whenever code changes.\n",
    "export_path = os.path.join(\n",
    "  tf.compat.as_bytes(\"./models/mnist\"),\n",
    "  tf.compat.as_bytes(str(1)))\n",
    "print('Exporting trained model to', export_path)\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "# Build the signature_def_map.\n",
    "classification_inputs = tf.saved_model.utils.build_tensor_info(\n",
    "  serialized_tf_example)\n",
    "classification_outputs_classes = tf.saved_model.utils.build_tensor_info(\n",
    "  prediction_classes)\n",
    "classification_outputs_scores = tf.saved_model.utils.build_tensor_info(values)\n",
    "\n",
    "classification_signature = (\n",
    "  tf.saved_model.signature_def_utils.build_signature_def(\n",
    "      inputs={\n",
    "          tf.saved_model.signature_constants.CLASSIFY_INPUTS:\n",
    "              classification_inputs\n",
    "      },\n",
    "      outputs={\n",
    "          tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:\n",
    "              classification_outputs_classes,\n",
    "          tf.saved_model.signature_constants.CLASSIFY_OUTPUT_SCORES:\n",
    "              classification_outputs_scores\n",
    "      },\n",
    "      method_name=tf.saved_model.signature_constants.CLASSIFY_METHOD_NAME))\n",
    "\n",
    "tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "tensor_info_y = tf.saved_model.utils.build_tensor_info(y)\n",
    "\n",
    "prediction_signature = (\n",
    "  tf.saved_model.signature_def_utils.build_signature_def(\n",
    "      inputs={'images': tensor_info_x},\n",
    "      outputs={'scores': tensor_info_y},\n",
    "      method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "builder.add_meta_graph_and_variables(\n",
    "  sess, [tf.saved_model.tag_constants.SERVING],\n",
    "  signature_def_map={\n",
    "      'predict_images':\n",
    "          prediction_signature,\n",
    "      tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "          classification_signature,\n",
    "  },\n",
    "  legacy_init_op=legacy_init_op)\n",
    "\n",
    "builder.save()\n",
    "\n",
    "print('Done exporting!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
